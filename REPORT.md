# Отчет
#### Изменения в коде

Сначала я фиксил баги. Первый из них был в `unet.py`, нужно было добавить размерность.


Было:
```
temb = self.timestep_embedding(t)
```
Стало: 
```
temb = self.timestep_embedding(t)[..., None, None]
```
Потом я прочитал статью и нашел ошибку в формуле в дифузии:

Было:
```
x_t = (... +self.one_minus_alpha_over_prod[...] * eps)
```
Стало: 
```
x_t = (... + self.sqrt_one_minus_alpha_prod[...]  * eps)
```

Потом уже начал фиксить баги в с девайсами, накинул так, чтобы все работало. 
Дальше я забил на написание тестов (но дописал их позже, опишу это).

### Hydra

Дальше мне захотелось прикрутить, так как это показалось достаточно просто и будет проще для wandb. В папке
configs лежит default.yaml, дефолтный конфиг, который мы потом будем оверрайдить 
через командную сроку. В этом конфиге содержатся все дефолтные параметры, имя проекта 
и также имя конфига (если зачем-то его захочется менять). Дальше нам нужно добавить декоратор
в `main.py`:

```
@hydra.main(version_base=None, config_path="configs", config_name="default")
def main(cfg: DictConfig):
    ....
```

Туда сразу протаскивается дефолтный конфиг, теперь в конце мы просто пишем:

```
if __name__ == "__main__":
    main()
```

Теперь можно достаточно просто все константы вставлять по типу:

```
ddpm = DiffusionModel(
        eps_model=UnetModel(*cfg.unet_params),
        betas=cfg.diffusion_params,
        num_timesteps=cfg.num_timesteps,
    )
```

Также там есть флажки на adam и sgd, флипы (их я просто ифами меняю, это не очень запарно).
Дальше можно запускать разные раны через командную строку.

Чтобы запустить дефолтный конфиг можно просто писать:
```
$ python main.py
```

Если я хочу поменять какие-то аргументы, то можно просто оверрайдить через командную строку 
(++ это добавить/поменять значение какого-то параметра). Я сделал два других рана, конфиг сохранил
и залогировал на wandb (об этом позже). (и когда я логировал, я на самом деле чуть-чуть так себе 
код запустил, можно было добавить `++cfg_name="что-то там"`, не убивайте плиз, просто забыл другие названия 
вставить, но в проекте в целом видно, что я могу менять название; но на самом деле прикольно,
что в wandb будет версионирование для штук с одним названием).

```
$ python main.py ++has_flips=True ++num_epochs=1 ++optimizer="sgd" 
```

```
$ python main.py ++has_flips=True ++num_epochs=1 ++optimizer="adam" ++lr=0.0001
```


Использованные конфиги я сохраняю я себе в папочку таким образом (это потом пригодиться для логирование конфига как кода на wandb)
```
if not os.path.exists("used_configs/"):
       os.makedirs("used_configs/")

OmegaConf.save(cfg, f"used_configs/used_config_{cfg.cfg_name}.yaml")
```
Если менять название файла, то он сохранится с соответствущим именем (это можно посмотреть будет на wandb). 
В целом Hydra позволяет удобнее работать гиперпараметрами, проще запускать эксперименты, но очевидно, что
она может больше (но мне показалось, что такой простенькой штуки для этого дз будет достаточно). 
Можно запускать конфиги отличные от дефолтных (`--config-name`).

### Wandb

Теперь расскажу про wandb. Понятно, что сначала нужно залогинить в проект. Я так как хотел просто запускать,
чтобы лишний раз не вводить api в колабе после изменения среды в конфиге держу `api_key` (я его уже в аккаунте удалил
так что не взломаете). Поэтому в main.py сразу логинимся:
```
wandb.login(key=cfg.api_key)
```
Дальше нужно заинитить проект:
```
wandb.init(project=cfg.name, config=OmegaConf.to_container(cfg), name=cfg.cfg_name)
```
Чтобы все было в одном проекте, мы просто будем в имя проекта запихивать `cfg.name`; чтобы получить
в wandb гиперпараметры у рана мы оберенем это в контейнер (при это если мы оверрайдим, то это все залогируется, 
получится табличка для разных запусков). Но кто-то говорил, что это не оч, так как не все может сохраниться, 
поэтому еще залогируем код конфига, с которым мы запускали. Делать это нужно с учетом оверрайда. Учитывая, что
мы сохраняем конфиги, мы можем их достать и залогировать:

```
wandb.run.log_code(root="used_configs", name=f"used_config_{cfg.cfg_name}.yaml",
                       include_fn=lambda path: path.endswith(".yaml"))
```

Дальше логирую инпуты, как и просили:

```
wandb.log({"inputs": [wandb.Image(img) for img in dataset.data[:64]]})
```
В training.py для каждого степа логирую лоссы:
```
wandb.log({'train_loss': train_loss.item(), 'train_loss_ema': loss_ema.item()})
```
После каждой эпохи логирую семплы c изначальным шумом (его я фиксирую в `trainig.py` 
на самой первой эпохе, там достаточно простое изменение кода) и learning rate:

```
wandb.log({"samples": wandb.Image(f"samples/{i:02d}.png"),
                       "lr": optim.param_groups[-1]["lr"]})
```

Чтобы картинки не были засвечены, после их генерации делаем clamp от -1 до 1, и делаем 
inverse transform с учетом нормализации (без этого картинки были бы засвечены), если
в wandb у меня прокрутить, то такого эффекта как будто нет (если конечно не генерируется
что-то в снегу и тд).

Вот ссылка на проект:

https://wandb.ai/aaplakhin/hw_edl_week_02/overview

В нем все логируется. Основной ран это `default main`. Там можно посмотреть на картинки. Учил с дефолтными параметрами.
Дальше есть два рана (для задания с гидрой) которые сделаны через оверрайд (где я не заоверрайдил название рана). 
Во кладке с артефактами есть залогированые конфиги (их можно достать из файлов при желании). Также там есть табличка,
где для каждого запуска показаны гиперпараметры. Тут есть еще 4 магических рана, они вылезли в тестирования:

### Тесты

Во-первых, тесты вроде бы норм. В `test_model.py` в функции test_diffusion я зафиксировал сид (иногда не проходит,
но это кажется нормальным, вроде бы в чате обсудили). Остальные написанные за нас тесты я не меня, но добавил свои.

`test_training_epoch_with_hydra` - тестится и на цпу и гпу. Он тестирует наш пайплайн в целом.
В нем подгружается дефолтный конфиг, меняется cfg_name (чтобы раны были с норм именем, запускается только одна эпоха и device.
Дальше запускается `main.py`, все логируется на wandb, в том числе и конфиг, с которым запускается код.
Если код тестируется на цпу, то для этого есть флажок (по умолчанию все на гпу).
Меняется датасет (берется 64 объекта и на них прогоняется код, чтобы не жадть тысячу лет,
но все-так протестировать код). Проверяется, что мы действительно сохранили конфиг, 
что он поменялся, а в случае гпу проверяется лосс и правда ли мы что-то засемплировали.

`test_with_different_hiden` - делает два запуска с разными параметрами unet. Делается два запуска
с разными параметрами (лосс для меньшего скрытого пространства должен быть больше, этот тут 
и проверяется). 






